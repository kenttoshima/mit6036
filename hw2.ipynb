{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_for_hw02_downloadable import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gen_big_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-4.97193554,  3.49851995,  4.00302943,  0.83369183,  0.41371989,\n",
       "          4.37614714,  1.03536965,  1.2354608 , -0.7933465 , -3.85456759],\n",
       "        [-0.92053415, -3.61953464,  0.39577344, -3.03202474, -4.90408303,\n",
       "         -0.10239158, -1.35546287,  1.31372748, -1.97924525, -3.72545813]]),\n",
       " array([[-1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = g(10)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(data, labels, params={}, hook=None):\n",
    "    # if T not in params, default to 100\n",
    "    T = params.get('T', 100)\n",
    "    # Your implementation here\n",
    "    th, th0 = np.zeros((data.shape[0], 1)), np.zeros((1, 1))\n",
    "    for _t in range(T):\n",
    "        for i in range(data.shape[1]):\n",
    "            if np.asscalar(labels[:, i] * (np.dot(th.T, data[:, i]) + th0)) <= 0:\n",
    "                th += labels[:, [i]] * data[:, [i]]\n",
    "                th0 += labels[:, [i]]\n",
    "    return th, th0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Perceptron 0-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Perceptron 1-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_perceptron(perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_perceptron(data, labels, params={}, hook=None):\n",
    "    # if T not in params, default to 100\n",
    "    T = params.get('T', 100)\n",
    "    # Your implementation here\n",
    "    th, th0 = np.zeros((data.shape[0], 1)), np.zeros((1, 1))\n",
    "    ths, th0s = np.zeros((data.shape[0], 1)), np.zeros((1, 1))\n",
    "    for _t in range(T):\n",
    "        for i in range(data.shape[1]):\n",
    "            if np.asscalar(labels[:, i] * (np.dot(th.T, data[:, i]) + th0)) <= 0:\n",
    "                th += labels[:, [i]] * data[:, [i]]\n",
    "                th0 += labels[:, [i]]\n",
    "            ths += th\n",
    "            th0s += th0\n",
    "    return ths / (data.shape[1] * T), th0s / (data.shape[1] * T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Averaged Perceptron 0-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Averaged Perceptron 1-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_averaged_perceptron(averaged_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(learner, data_train, labels_train, data_test, labels_test):\n",
    "    th, th0 = learner(data_train, labels_train)\n",
    "    return score(data_test, labels_test, th, th0) / data_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Eval Classifier 0-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Eval Classifier 1-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_eval_classifier(eval_classifier,perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_learning_alg(learner, data_gen, n_train, n_test, it):\n",
    "    score_sum = 0\n",
    "    for _i in range(it):\n",
    "        data_train, labels_train = data_gen(n_train)\n",
    "        data_test, labels_test = data_gen(n_test)\n",
    "        score_sum += eval_classifier(learner, data_train, labels_train, data_test, labels_test)\n",
    "    return score_sum / it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Eval Learning Algo-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_eval_learning_alg(eval_learning_alg,perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xval_learning_alg(learner, data, labels, k):\n",
    "    #cross validation of learning algorithm\n",
    "    subdata = np.array_split(data, k, axis=1)\n",
    "    sublabels = np.array_split(labels, k, axis=1)\n",
    "    score_sum = 0\n",
    "    for i in range(k):\n",
    "        array_data = subdata[:i] + subdata[i+1:]\n",
    "        array_label = sublabels[:i] + sublabels[i+1:]\n",
    "        data_train = np.concatenate(array_data, axis=1)\n",
    "        labels_train = np.concatenate(array_label, axis=1)\n",
    "        data_test = subdata[i]\n",
    "        labels_test = sublabels[i]\n",
    "        score_sum += eval_classifier(learner, data_train, labels_train, data_test, labels_test)\n",
    "    return score_sum / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Cross-eval Learning Algo-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_xval_learning_alg(xval_learning_alg,perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6383999999999996"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen = gen_flipped_lin_separable(pflip=0.25)\n",
    "eval_learning_alg(averaged_perceptron, data_gen, n_train=20, n_test=20, it=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_eval_learning_alg(learner, data_gen, n_train, it):\n",
    "    score_sum = 0\n",
    "    for _i in range(it):\n",
    "        data_train, labels_train = data_gen(n_train)\n",
    "        data_test, labels_test = data_train, labels_train\n",
    "        score_sum += eval_classifier(learner, data_train, labels_train, data_test, labels_test)\n",
    "    return score_sum / it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7286999999999998"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen = gen_flipped_lin_separable(pflip=0.25)\n",
    "mod_eval_learning_alg(averaged_perceptron, data_gen, n_train=20, it=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
