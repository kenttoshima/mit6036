{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_for_hw3_part2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_auto_data('auto-mpg.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = [('cylinders', raw),\n",
    "             ('displacement', raw),\n",
    "             ('horsepower', raw),\n",
    "             ('weight', raw),\n",
    "             ('acceleration', raw),\n",
    "             ## Drop model_year by default\n",
    "             ## ('model_year', hw3.raw),\n",
    "             ('origin', raw)]\n",
    "features2 = [('cylinders', one_hot),\n",
    "             ('displacement', standard),\n",
    "             ('horsepower', standard),\n",
    "             ('weight', standard),\n",
    "             ('acceleration', standard),\n",
    "             ## Drop model_year by default\n",
    "             ## ('model_year', hw3.raw),\n",
    "             ('origin', one_hot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto data and labels shape (8, 392) (1, 392)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('auto data and labels shape', auto_data.shape, auto_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg and std {}\n",
      "entries in one_hot field {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6909615384615384, 0.8366025641025641)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 50\n",
    "learner = perceptron\n",
    "auto_data, auto_labels = auto_data_and_labels(data, features1)\n",
    "a = xval_learning_alg(lambda data, labels: learner(data, labels, {\"T\": T}), \n",
    "                      auto_data, auto_labels, 10)\n",
    "learner = averaged_perceptron\n",
    "b = xval_learning_alg(lambda data, labels: learner(data, labels, {\"T\": T}), \n",
    "                      auto_data, auto_labels, 10)\n",
    "(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg and std {'displacement': (388.3482142857143, 302.0458123396403), 'horsepower': (509.3545918367347, 333.6521151716361), 'weight': (2977.5841836734694, 848.3184465698365), 'acceleration': (15.541326530612228, 2.7553429127509963)}\n",
      "entries in one_hot field {'cylinders': [3.0, 4.0, 5.0, 6.0, 8.0], 'origin': [1.0, 2.0, 3.0]}\n"
     ]
    }
   ],
   "source": [
    "auto_data, auto_labels = auto_data_and_labels(data, features2)\n",
    "th, _ = averaged_perceptron(auto_data, auto_labels, params = {'T': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.25510204],\n",
       "        [ 0.98469388],\n",
       "        [ 0.        ],\n",
       "        [ 0.4744898 ],\n",
       "        [-0.52040816],\n",
       "        [ 0.0977406 ],\n",
       "        [-0.89763413],\n",
       "        [-1.84711922],\n",
       "        [ 0.06270238],\n",
       "        [-0.04591837],\n",
       "        [ 0.98469388],\n",
       "        [-0.25510204]]), 1, 0.9846938775510204)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th, th.argmax(), th.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., ..., 0., 1., 1.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 1., ..., 1., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[-1, -1, -1, ...,  1,  1, -1]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data = load_review_data('reviews.tsv')\n",
    "# Lists texts of reviews and list of labels (1 or -1)\n",
    "review_texts, review_label_list = zip(*((sample['text'], sample['sentiment']) for sample in review_data))\n",
    "# The dictionary of all the words for \"bag of words\"\n",
    "dictionary = bag_of_words(review_texts)\n",
    "review_bow_data = extract_bow_feature_vectors(review_texts, dictionary)\n",
    "review_labels = rv(review_label_list)\n",
    "review_bow_data, review_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7672000000000001, 0.8120999999999998]\n",
      "[0.7871, 0.8237]\n",
      "[0.8036, 0.8157]\n"
     ]
    }
   ],
   "source": [
    "t_list = [1, 10, 50]\n",
    "algs = [perceptron, averaged_perceptron]\n",
    "acc = [None, None]\n",
    "for t in t_list:\n",
    "    for i, alg in enumerate(algs):\n",
    "        acc[i] = xval_learning_alg(lambda data, labels: alg(data, labels, {\"T\": t}), \n",
    "                                   review_bow_data, review_labels, 10)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numpy.core.fromnumeric.argsort(a, axis=-1, kind='quicksort', order=None)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_dict\n",
    "np.argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.15984],\n",
       "        [-2.74048],\n",
       "        [-1.23668],\n",
       "        ...,\n",
       "        [ 0.     ],\n",
       "        [-1.2001 ],\n",
       "        [ 0.     ]]), array([[-1.72795]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th, th0 = averaged_perceptron(review_bow_data, review_labels, params = {'T': 10})\n",
    "th, th0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[305, 492, 2352, 2003, 2633, 3126, 2877, 2571, 1406, 2424]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argarr = np.argsort(th, axis=0)\n",
    "idxs = argarr[0:10, 0].tolist()\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_dict = reverse_dict(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'awful',\n",
       " 'unfortunately',\n",
       " 'horrible',\n",
       " 'stuck',\n",
       " 'changed',\n",
       " 'disappointment',\n",
       " 'bland',\n",
       " 'poor',\n",
       " 'formula']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda key: rev_dict[key], idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3011, 56, 2213, 2329, 1476, 2413, 356, 1896, 1105, 348]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argarr = np.argsort(th, axis=0)\n",
    "idxs = argarr[-11:-1, 0].tolist()\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['delighted',\n",
       " 'great',\n",
       " 'individually',\n",
       " 'bright',\n",
       " 'yummy',\n",
       " 'skeptical',\n",
       " 'perfect',\n",
       " 'easily',\n",
       " 'satisfied',\n",
       " 'delicious']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda key: rev_dict[key], idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_average_features(x):\n",
    "    \"\"\"\n",
    "    @param x (m,n) array with values in (0,1)\n",
    "    @return (m,1) array where each entry is the average of a row\n",
    "    \"\"\"\n",
    "    return np.mean(x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_average_features(x):\n",
    "    \"\"\"\n",
    "    @param x (m,n) array with values in (0,1)\n",
    "    @return (n,1) array where each entry is the average of a column\n",
    "    \"\"\"\n",
    "    return np.mean(x, axis=0, keepdims=True).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((5, 4))\n",
    "print(row_average_features(x))\n",
    "print(col_average_features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_mnist_features(x):\n",
    "    \"\"\"\n",
    "    @param x (n_samples,m,n) array with values in (0,1)\n",
    "    @return (m*n,n_samples) reshaped array where each entry is preserved\n",
    "    \"\"\"\n",
    "    n_samples, m, n = x.shape\n",
    "    return x.reshape(n_samples, m * n).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_average_features(x):\n",
    "    \"\"\"\n",
    "    @param x (n_samples,m,n) array with values in (0,1)\n",
    "    @return (m,n_samples) array where each entry is the average of a row\n",
    "    \"\"\"\n",
    "    return np.mean(x, axis=2, keepdims=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_average_features(x):\n",
    "    \"\"\"\n",
    "    @param x (n_samples,m,n) array with values in (0,1)\n",
    "    @return (n,n_samples) array where each entry is the average of a column\n",
    "    \"\"\"\n",
    "    return np.mean(x, axis=1, keepdims=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_bottom_features(x):\n",
    "    \"\"\"\n",
    "    @param x (n_samples,m,n) array with values in (0,1)\n",
    "    @return (2,n_samples) array where the first entry of each column is the average of the\n",
    "    top half of the image = rows 0 to floor(m/2) [exclusive]\n",
    "    and the second entry is the average of the bottom half of the image\n",
    "    = rows floor(m/2) [inclusive] to m\n",
    "    \"\"\"\n",
    "    n_samples, m, n = x.shape\n",
    "    return cv([np.mean(x[:, 0:m//2, :], axis=(1, 2)), np.mean(x[:, m//2:m, :], axis=(1, 2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.975, 0.8641666666666665, 0.9479166666666667, 0.6470833333333333]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [(0, 1), (2, 4), (6, 8), (9, 0)]\n",
    "for i in range(len(lst)):\n",
    "    a, b = lst[i]\n",
    "    mnist_data_all = load_mnist_data(range(10))\n",
    "    d0 = mnist_data_all[a][\"images\"]\n",
    "    d1 = mnist_data_all[b][\"images\"]\n",
    "    y0 = np.repeat(-1, len(d0)).reshape(1,-1)\n",
    "    y1 = np.repeat(1, len(d1)).reshape(1,-1)\n",
    "    # data goes into the feature computation functions\n",
    "    data = np.vstack((d0, d1))\n",
    "    # labels can directly go into the perceptron algorithm\n",
    "    labels = np.vstack((y0.T, y1.T)).T\n",
    "    lst[i] = get_classification_accuracy(raw_mnist_features(data), labels)\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 160)\n",
      "(28, 160)\n",
      "(28, 160)\n",
      "(160, 2, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-bf985b88718c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_classification_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/mit6036/hw3/code_for_hw3_part2.py\u001b[0m in \u001b[0;36mget_classification_accuracy\u001b[0;34m(data, labels)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxval_learning_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mperceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/mit6036/hw3/code_for_hw3_part2.py\u001b[0m in \u001b[0;36mxval_learning_alg\u001b[0;34m(learner, data, labels, k)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mxval_learning_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "lst = [raw_mnist_features, row_average_features, col_average_features, top_bottom_features]\n",
    "acc = []\n",
    "mnist_data_all = load_mnist_data(range(10))\n",
    "d0 = mnist_data_all[0][\"images\"]\n",
    "d1 = mnist_data_all[1][\"images\"]\n",
    "y0 = np.repeat(-1, len(d0)).reshape(1,-1)\n",
    "y1 = np.repeat(1, len(d1)).reshape(1,-1)\n",
    "for feature in lst:\n",
    "    # data goes into the feature computation functions\n",
    "    data = np.vstack((d0, d1))\n",
    "    # labels can directly go into the perceptron algorithm\n",
    "    labels = np.vstack((y0.T, y1.T)).T\n",
    "#     print(feature(data).shape)\n",
    "    acc.append(get_classification_accuracy(feature(data), labels))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
